<h3 id="article-level-metrics">Article-level metrics</h3>
<p>An obvious way to overcome the logical and practical problems of using journal-level metrics to evaluate the quality of the articles, is to base evaluations on the articles themselves. Various article-level metrics are available to do this.</p>
<h4 id="h-index"><em>h</em>-Index</h4>
<blockquote>
<p>“Here, I would like to propose a single number, the ‘<em>h</em> index,’ as a particularly simple and useful way to characterize the scientific output of a researcher.” (Hirsch 2005)</p>
</blockquote>
<p>The “<em>h</em>-index” is indeed a simple metric. To find the <em>h</em>-index of a researcher, take all the articles that the researcher has published, and sort them in ascending order of how many citations each has received. Then start counting the articles, starting with the one with the least number of citations; when you come to an article which has a number of citations equal to the count of articles so far, that article/citation count is the <em>h</em>-index for the researcher. For example, a researcher who has an <em>h</em>-index of 6 has six published articles with at least six citations each.</p>
<p>The <em>h</em>-index is popular enough to have prompt the creation of various refinements to the basic method, e.g., the g-index (Egghe 2013) and the <i>h</i><sup>m</sup>-index (Schreiber 2008). And of the three citation metrics displayed on a Google Scholar user's citations page<sup><a href="#footnote">†</a></sup>, one is the <em>h</em>-index, and another is a variant of the <em>h</em>-index, the i10-index (Connor 2011). (The third is simply a count of total citations.)</p>
<p>Yet, the usefulness of the <em>h</em>-index is unclear. In the original proposal, the index was offered as a quantitative metric to be used “for evaluation and comparison purposes” (Hirsch 2005). To demonstrate this use the author reported the <em>h</em>-index value for a collection of example researchers, including Nobel-prie winners. But, as Adler <em>et al.</em> explain:</p>
<blockquote>
<p>“One can conclude that it is likely a scientist has a high h-index given the scientist is a Nobel Laureate. But without further information, we know very little about the likelihood someone will become a Nobel Laureate or a member of the National Academy, given that they have a high h-index.” (Adler <em>et al.</em> 2009)</p>
</blockquote>
<p>Indeed, the <em>h</em>-index has be shown to be inferior to equally simple metrics: “Compared with the h-index, the mean number of citations per paper is a superior indicator of scientific quality, in terms of both accuracy and precision.” (Lehmann 2006).</p>
<p>Though, there is a more important question to ask than which of the simple, article-level metrics is a better indicator of research quality—are any of them actually useful? Evaluating the quality of the work being done by a researcher is not a simple task, so any simple tool will inevitably prove to be inadequate. In reference to the h-<em>index</em> and a number variants of it, Adler <em>et al.</em> write:</p>
<blockquote>
<p>“These are often breathtakingly naïve attempts to capture a complex citation record with a single number. Indeed, the primary advantage of these new indices… is that the indices discard almost all the detail of citation records, and this makes it possible to rank any two scientists. Even simple examples, however, show that the discarded information is needed to understand a research record.” (Adler <em>et al.</em> 2009)</p>
</blockquote>
<p>Notes:</p>
<p><a name="footnote">†</a> – See, for example, <a href="https://scholar.google.com/citations?user=ZhuI0gwAAAAJ">scholar.google.com/citations?user=ZhuI0gwAAAAJ</a>.</p>
